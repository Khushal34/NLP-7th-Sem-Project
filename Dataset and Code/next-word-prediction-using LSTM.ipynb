{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "349d815f",
   "metadata": {
    "papermill": {
     "duration": 0.005979,
     "end_time": "2024-11-12T16:37:58.865015",
     "exception": false,
     "start_time": "2024-11-12T16:37:58.859036",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This code imports necessary libraries and reads a text file for further processing:\r\n",
    "\r\n",
    "1**Imports****:\r\n",
    "   - `import numpy as np`: Imports the NumPy library for numerical operations, commonly used for handling arrays and matrices.\r\n",
    "   - `import tensorflow as tf`: Imports TensorFlow for building and training machine learning models.\r\n",
    "   - `from tensorflow.keras.preprocessing.text import Tokenizer`: Imports the `Tokenizer` class for converting text into sequences of integers.\r\n",
    "   - `from tensorflow.keras.preprocessing.sequence import pad_sequences`: Imports a method to ensure input sequences have the same length by padding them.\r\n",
    "   - `from tensorflow.keras.models import Sequential`: Imports the Sequential model, a linear stack of layers for building models.\r\n",
    "   - `from tensorflow.keras.layers import Embedding, LSTM, Dense`: Imports specific layers for the model (Embedding for word representations, LSTM for sequence processing, Dense for fully connected layers).\r\n",
    "   - `from tensorflow.keras.optimizers import Adam`: Imports the Adam optimizer for training tmodel training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f70c0fd",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-12T16:37:58.876940Z",
     "iopub.status.busy": "2024-11-12T16:37:58.876501Z",
     "iopub.status.idle": "2024-11-12T16:38:12.465472Z",
     "shell.execute_reply": "2024-11-12T16:38:12.464513Z"
    },
    "papermill": {
     "duration": 13.597657,
     "end_time": "2024-11-12T16:38:12.467950",
     "exception": false,
     "start_time": "2024-11-12T16:37:58.870293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Read the text file\n",
    "with open('/kaggle/input/next-word-prediction/sherlock-holm.es_stories_plain-text_advs.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec6e9b9",
   "metadata": {
    "papermill": {
     "duration": 0.004814,
     "end_time": "2024-11-12T16:38:12.478047",
     "exception": false,
     "start_time": "2024-11-12T16:38:12.473233",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This code sets up a tokenizer to process the text, creates a mapping of each unique word to a number, and calculates the total number of words (including a padding token)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0be39989",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T16:38:12.489475Z",
     "iopub.status.busy": "2024-11-12T16:38:12.488930Z",
     "iopub.status.idle": "2024-11-12T16:38:12.638231Z",
     "shell.execute_reply": "2024-11-12T16:38:12.637446Z"
    },
    "papermill": {
     "duration": 0.157529,
     "end_time": "2024-11-12T16:38:12.640590",
     "exception": false,
     "start_time": "2024-11-12T16:38:12.483061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "total_words = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0895b900",
   "metadata": {
    "papermill": {
     "duration": 0.004909,
     "end_time": "2024-11-12T16:38:12.651555",
     "exception": false,
     "start_time": "2024-11-12T16:38:12.646646",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This code creates input sequences for training the model:\r\n",
    "\r\n",
    "1. **`input_sequences = []`**: Initializes an empty list to store the sequences.\r\n",
    "\r\n",
    "2. **`for line in text.split('\\n'):`**: Loops through each line of the text (split by newline).\r\n",
    "\r\n",
    "3. **`token_list = tokenizer.texts_to_sequences([line])[0]`**: Converts each line of text into a sequence of integers (tokens) based on the tokenizer's word index.\r\n",
    "\r\n",
    "4. **`for i in range(1, len(token_list)):`**: Loops through each token in the `token_list`, starting from the second token.\r\n",
    "\r\n",
    "5. **`n_gram_sequence = token_list[:i+1]`**: Creates an n-gram sequence by taking the first `i+1` tokens from the `token_list`.\r\n",
    "\r\n",
    "6. **`input_sequences.append(n_gram_sequence)`**: Appends each n-gram sequence to the `input_sequences` list.\r\n",
    "\r\n",
    "This process generates sequences of words (n-grams) that the model will use to learn context and predict the next word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa5470e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T16:38:12.662858Z",
     "iopub.status.busy": "2024-11-12T16:38:12.662542Z",
     "iopub.status.idle": "2024-11-12T16:38:13.115283Z",
     "shell.execute_reply": "2024-11-12T16:38:13.114370Z"
    },
    "papermill": {
     "duration": 0.461361,
     "end_time": "2024-11-12T16:38:13.117834",
     "exception": false,
     "start_time": "2024-11-12T16:38:12.656473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "for line in text.split('\\n'):\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e791b89d",
   "metadata": {
    "papermill": {
     "duration": 0.00794,
     "end_time": "2024-11-12T16:38:13.143455",
     "exception": false,
     "start_time": "2024-11-12T16:38:13.135515",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This ensures all input sequences are of equal length, which is required for training a machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebdaff17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T16:38:13.155881Z",
     "iopub.status.busy": "2024-11-12T16:38:13.155480Z",
     "iopub.status.idle": "2024-11-12T16:38:13.607096Z",
     "shell.execute_reply": "2024-11-12T16:38:13.605944Z"
    },
    "papermill": {
     "duration": 0.460737,
     "end_time": "2024-11-12T16:38:13.609766",
     "exception": false,
     "start_time": "2024-11-12T16:38:13.149029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_sequence_len = max([len(seq) for seq in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdad67c9",
   "metadata": {
    "papermill": {
     "duration": 0.005198,
     "end_time": "2024-11-12T16:38:13.620073",
     "exception": false,
     "start_time": "2024-11-12T16:38:13.614875",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This code splits the input sequences into features (X) and labels (y):\n",
    "\n",
    "X = input_sequences[:, :-1]:\n",
    "\n",
    "X contains all tokens in the input sequences except the last token. This is done by selecting all columns except the last one (:-1), which represents the context (previous words) for the prediction.\n",
    "y = input_sequences[:, -1]:\n",
    "\n",
    "y contains only the last token of each sequence (-1), which is the target word that the model will predict based on the context (X)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db1a3650",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T16:38:13.631506Z",
     "iopub.status.busy": "2024-11-12T16:38:13.631165Z",
     "iopub.status.idle": "2024-11-12T16:38:13.635741Z",
     "shell.execute_reply": "2024-11-12T16:38:13.634975Z"
    },
    "papermill": {
     "duration": 0.012675,
     "end_time": "2024-11-12T16:38:13.637944",
     "exception": false,
     "start_time": "2024-11-12T16:38:13.625269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = input_sequences[:, :-1]\n",
    "y = input_sequences[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172d35b4",
   "metadata": {
    "papermill": {
     "duration": 0.004695,
     "end_time": "2024-11-12T16:38:13.647616",
     "exception": false,
     "start_time": "2024-11-12T16:38:13.642921",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This step prepares the labels in a format suitable for training a classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e22bea6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T16:38:13.658639Z",
     "iopub.status.busy": "2024-11-12T16:38:13.658288Z",
     "iopub.status.idle": "2024-11-12T16:38:17.870920Z",
     "shell.execute_reply": "2024-11-12T16:38:17.870068Z"
    },
    "papermill": {
     "duration": 4.220855,
     "end_time": "2024-11-12T16:38:17.873383",
     "exception": false,
     "start_time": "2024-11-12T16:38:13.652528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = np.array(tf.keras.utils.to_categorical(y, num_classes=total_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94181829",
   "metadata": {
    "papermill": {
     "duration": 0.005018,
     "end_time": "2024-11-12T16:38:17.884040",
     "exception": false,
     "start_time": "2024-11-12T16:38:17.879022",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This code defines, builds, and compiles a neural network model for next-word prediction:\r\n",
    "\r\n",
    "1. **Model Definition**:\r\n",
    "   - `model = Sequential()`: Creates a sequential model, where layers are stacked one after the other.\r\n",
    "   - `model.add(Embedding(input_dim=total_words, output_dim=100, input_length=max_sequence_len-1))`: Adds an embedding layer that converts integer sequences into dense vectors of fixed size (100). The input dimension is the total number of words (vocabulary size), and the input length is the length of each sequence (one less than the max sequence length).\r\n",
    "   - `model.add(LSTM(150))`: Adds a Long Short-Term Memory (LSTM) layer with 150 units. LSTM is used for processing sequential data.\r\n",
    "   - `model.add(Dense(total_words, activation='softmax'))`: Adds a dense layer with `total_words` output units and a softmax activation function, which will output a probability distribution over the vocabulary for the predicted next word.\r\n",
    "\r\n",
    "2. **Model Build**:\r\n",
    "   - `model.build(input_shape=(None, max_sequence_len-1))`: Explicitly builds the model by specifying the shape of the input data (sequences of length `max_sequence_len-1`).\r\n",
    "\r\n",
    "3. **Model Compilation**:\r\n",
    "   - `adam = Adam(learning_rate=0.01)`: Initializes the Adam optimizer with a learning rate of 0.01.\r\n",
    "   - `model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])`: Compiles the model with categorical crossentropy loss (for multi-class classification) and the Adam optimizer. The accuracy metric is used to evaluate the model.\r\n",
    "\r\n",
    "4. **Model Summary**:\r\n",
    "   - `print(model.summary())`: Prints a summary of the model, including the number of parameters in each layer.\r\n",
    "\r\n",
    "This sets up the model for training next-word prediction based on the input sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c88fbe33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T16:38:17.894899Z",
     "iopub.status.busy": "2024-11-12T16:38:17.894603Z",
     "iopub.status.idle": "2024-11-12T16:38:19.317877Z",
     "shell.execute_reply": "2024-11-12T16:38:19.316867Z"
    },
    "papermill": {
     "duration": 1.431785,
     "end_time": "2024-11-12T16:38:19.320723",
     "exception": false,
     "start_time": "2024-11-12T16:38:17.888938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">820,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">150,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8200</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,238,200</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │       \u001b[38;5;34m820,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │       \u001b[38;5;34m150,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8200\u001b[0m)           │     \u001b[38;5;34m1,238,200\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,208,800</span> (8.43 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,208,800\u001b[0m (8.43 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,208,800</span> (8.43 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,208,800\u001b[0m (8.43 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=total_words, output_dim=100, input_length=max_sequence_len-1))\n",
    "model.add(LSTM(150))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "# Build the model explicitly to avoid 'unbuilt' state\n",
    "model.build(input_shape=(None, max_sequence_len-1))\n",
    "\n",
    "# Compile the model\n",
    "adam = Adam(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary to verify parameter count\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39bb07d",
   "metadata": {
    "papermill": {
     "duration": 0.00587,
     "end_time": "2024-11-12T16:38:19.332697",
     "exception": false,
     "start_time": "2024-11-12T16:38:19.326827",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This trains the model to predict the next word based on context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f1818e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T16:38:19.345985Z",
     "iopub.status.busy": "2024-11-12T16:38:19.345348Z",
     "iopub.status.idle": "2024-11-12T17:11:16.921416Z",
     "shell.execute_reply": "2024-11-12T17:11:16.920232Z"
    },
    "papermill": {
     "duration": 1977.584879,
     "end_time": "2024-11-12T17:11:16.923455",
     "exception": false,
     "start_time": "2024-11-12T16:38:19.338576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - accuracy: 0.0621 - loss: 6.5480\n",
      "Epoch 2/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.1166 - loss: 5.5604\n",
      "Epoch 3/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.1448 - loss: 5.1421\n",
      "Epoch 4/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.1653 - loss: 4.7772\n",
      "Epoch 5/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.1844 - loss: 4.4606\n",
      "Epoch 6/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.2050 - loss: 4.1594\n",
      "Epoch 7/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.2332 - loss: 3.8829\n",
      "Epoch 8/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.2647 - loss: 3.6185\n",
      "Epoch 9/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.3003 - loss: 3.3662\n",
      "Epoch 10/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.3369 - loss: 3.1408\n",
      "Epoch 11/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.3690 - loss: 2.9474\n",
      "Epoch 12/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.4050 - loss: 2.7539\n",
      "Epoch 13/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.4388 - loss: 2.5618\n",
      "Epoch 14/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.4694 - loss: 2.4147\n",
      "Epoch 15/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.5013 - loss: 2.2616\n",
      "Epoch 16/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.5265 - loss: 2.1218\n",
      "Epoch 17/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.5530 - loss: 2.0044\n",
      "Epoch 18/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.5792 - loss: 1.8872\n",
      "Epoch 19/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.6017 - loss: 1.7846\n",
      "Epoch 20/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.6222 - loss: 1.6998\n",
      "Epoch 21/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.6427 - loss: 1.5989\n",
      "Epoch 22/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.6611 - loss: 1.5096\n",
      "Epoch 23/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.6778 - loss: 1.4306\n",
      "Epoch 24/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.6910 - loss: 1.3686\n",
      "Epoch 25/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.7116 - loss: 1.2886\n",
      "Epoch 26/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.7233 - loss: 1.2342\n",
      "Epoch 27/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.7327 - loss: 1.1887\n",
      "Epoch 28/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.7461 - loss: 1.1330\n",
      "Epoch 29/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.7562 - loss: 1.0890\n",
      "Epoch 30/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.7645 - loss: 1.0466\n",
      "Epoch 31/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.7725 - loss: 1.0103\n",
      "Epoch 32/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.7800 - loss: 0.9663\n",
      "Epoch 33/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.7899 - loss: 0.9285\n",
      "Epoch 34/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.7948 - loss: 0.8993\n",
      "Epoch 35/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8020 - loss: 0.8716\n",
      "Epoch 36/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8058 - loss: 0.8468\n",
      "Epoch 37/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.8121 - loss: 0.8262\n",
      "Epoch 38/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8195 - loss: 0.7932\n",
      "Epoch 39/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8214 - loss: 0.7809\n",
      "Epoch 40/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8246 - loss: 0.7579\n",
      "Epoch 41/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8289 - loss: 0.7450\n",
      "Epoch 42/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.8335 - loss: 0.7233\n",
      "Epoch 43/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8353 - loss: 0.7085\n",
      "Epoch 44/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8375 - loss: 0.6933\n",
      "Epoch 45/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.8434 - loss: 0.6726\n",
      "Epoch 46/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8434 - loss: 0.6698\n",
      "Epoch 47/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8473 - loss: 0.6491\n",
      "Epoch 48/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8486 - loss: 0.6418\n",
      "Epoch 49/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8521 - loss: 0.6305\n",
      "Epoch 50/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.8543 - loss: 0.6184\n",
      "Epoch 51/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8546 - loss: 0.6142\n",
      "Epoch 52/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8570 - loss: 0.6021\n",
      "Epoch 53/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.8608 - loss: 0.5922\n",
      "Epoch 54/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8592 - loss: 0.5854\n",
      "Epoch 55/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.8605 - loss: 0.5773\n",
      "Epoch 56/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8612 - loss: 0.5781\n",
      "Epoch 57/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8636 - loss: 0.5661\n",
      "Epoch 58/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.8628 - loss: 0.5664\n",
      "Epoch 59/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8655 - loss: 0.5568\n",
      "Epoch 60/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8645 - loss: 0.5550\n",
      "Epoch 61/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8676 - loss: 0.5467\n",
      "Epoch 62/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8675 - loss: 0.5409\n",
      "Epoch 63/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.8692 - loss: 0.5347\n",
      "Epoch 64/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8695 - loss: 0.5342\n",
      "Epoch 65/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8705 - loss: 0.5294\n",
      "Epoch 66/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.8669 - loss: 0.5324\n",
      "Epoch 67/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8721 - loss: 0.5139\n",
      "Epoch 68/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.8698 - loss: 0.5215\n",
      "Epoch 69/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8732 - loss: 0.5143\n",
      "Epoch 70/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8706 - loss: 0.5220\n",
      "Epoch 71/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.8745 - loss: 0.5036\n",
      "Epoch 72/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8728 - loss: 0.5077\n",
      "Epoch 73/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8751 - loss: 0.5026\n",
      "Epoch 74/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8747 - loss: 0.5005\n",
      "Epoch 75/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.8757 - loss: 0.4956\n",
      "Epoch 76/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.8770 - loss: 0.4898\n",
      "Epoch 77/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8756 - loss: 0.4934\n",
      "Epoch 78/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8731 - loss: 0.4986\n",
      "Epoch 79/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8755 - loss: 0.4910\n",
      "Epoch 80/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.8782 - loss: 0.4794\n",
      "Epoch 81/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8777 - loss: 0.4847\n",
      "Epoch 82/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8770 - loss: 0.4860\n",
      "Epoch 83/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.8751 - loss: 0.4861\n",
      "Epoch 84/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8765 - loss: 0.4781\n",
      "Epoch 85/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.8766 - loss: 0.4781\n",
      "Epoch 86/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8746 - loss: 0.4820\n",
      "Epoch 87/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8769 - loss: 0.4777\n",
      "Epoch 88/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8771 - loss: 0.4794\n",
      "Epoch 89/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8794 - loss: 0.4682\n",
      "Epoch 90/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8793 - loss: 0.4718\n",
      "Epoch 91/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8754 - loss: 0.4781\n",
      "Epoch 92/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.8781 - loss: 0.4732\n",
      "Epoch 93/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8763 - loss: 0.4741\n",
      "Epoch 94/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8777 - loss: 0.4693\n",
      "Epoch 95/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.8768 - loss: 0.4689\n",
      "Epoch 96/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8790 - loss: 0.4662\n",
      "Epoch 97/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.8799 - loss: 0.4616\n",
      "Epoch 98/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8810 - loss: 0.4597\n",
      "Epoch 99/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.8819 - loss: 0.4532\n",
      "Epoch 100/100\n",
      "\u001b[1m3010/3010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8797 - loss: 0.4606\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x788fcd81b640>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a373bb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T17:11:23.805152Z",
     "iopub.status.busy": "2024-11-12T17:11:23.804762Z",
     "iopub.status.idle": "2024-11-12T17:11:24.259094Z",
     "shell.execute_reply": "2024-11-12T17:11:24.257858Z"
    },
    "papermill": {
     "duration": 3.875782,
     "end_time": "2024-11-12T17:11:24.261682",
     "exception": false,
     "start_time": "2024-11-12T17:11:20.385900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Hi my name is  sherlock holmes it is my\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"Hi my name is \"\n",
    "next_words = 5\n",
    "\n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted = np.argmax(model.predict(token_list), axis=-1)\n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted:\n",
    "            output_word = word\n",
    "            break\n",
    "    seed_text += \" \" + output_word\n",
    "\n",
    "print(seed_text)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6045107,
     "sourceId": 9851668,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2014.43854,
   "end_time": "2024-11-12T17:11:30.435412",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-12T16:37:55.996872",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
